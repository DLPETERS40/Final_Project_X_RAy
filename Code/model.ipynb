{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e7e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "#Load and inspect images using the Python Imaging Library (PIL)\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing training data set\n",
    "path = 'augmented_xray_images.pkl'\n",
    "with open(path, 'rb') as file:\n",
    "    X_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c266f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read y training labels for images from csv file\n",
    "y_train = np.loadtxt('y_augmented_labels.txt')\n",
    "# display y_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9961f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing training data set\n",
    "path = 'testing_xray_images.pkl'\n",
    "with open(path, 'rb') as file:\n",
    "    X_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982cd1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read y training labels for images from csv file\n",
    "y_test = np.loadtxt('y_testing_labels.txt')\n",
    "# display y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12be896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define x shape\n",
    "X_shape = X_train[0].shape\n",
    "# print shape\n",
    "X_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16601528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test= np.array(X_test)\n",
    "y_train= np.array(y_train)\n",
    "y_test= np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f761d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test data for the model\n",
    "X_test_np = []\n",
    "for img in X_test:\n",
    "    # Add a channel dimension for grayscale images\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    # Append the image to the list\n",
    "    X_test_np.append(img)\n",
    "\n",
    "# Convert to numpy array\n",
    "X_test_np = np.array(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 340ms/step - accuracy: 0.2155 - loss: 44.4559 - val_accuracy: 0.2628 - val_loss: 16.1840\n",
      "Epoch 2/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 338ms/step - accuracy: 0.2280 - loss: 15.8965 - val_accuracy: 0.2628 - val_loss: 15.4507\n",
      "Epoch 3/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 334ms/step - accuracy: 0.2305 - loss: 15.5226 - val_accuracy: 0.2628 - val_loss: 15.5810\n",
      "Epoch 4/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 334ms/step - accuracy: 0.2305 - loss: 15.5385 - val_accuracy: 0.2628 - val_loss: 15.4614\n",
      "Epoch 5/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 334ms/step - accuracy: 0.2312 - loss: 15.5486 - val_accuracy: 0.2628 - val_loss: 16.1233\n",
      "Epoch 6/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 333ms/step - accuracy: 0.2322 - loss: 15.5563 - val_accuracy: 0.2628 - val_loss: 15.6654\n",
      "Epoch 7/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 337ms/step - accuracy: 0.2251 - loss: 15.5596 - val_accuracy: 0.2628 - val_loss: 15.2835\n",
      "Epoch 8/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 342ms/step - accuracy: 0.2315 - loss: 15.5782 - val_accuracy: 0.2628 - val_loss: 15.6300\n",
      "Epoch 9/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 337ms/step - accuracy: 0.2332 - loss: 15.5656 - val_accuracy: 0.2628 - val_loss: 15.7462\n",
      "Epoch 10/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 338ms/step - accuracy: 0.2337 - loss: 15.5688 - val_accuracy: 0.2628 - val_loss: 15.6117\n",
      "Epoch 11/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 335ms/step - accuracy: 0.2322 - loss: 15.5668 - val_accuracy: 0.2628 - val_loss: 15.7770\n",
      "Epoch 12/15\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 336ms/step - accuracy: 0.2307 - loss: 15.5635 - val_accuracy: 0.2628 - val_loss: 15.4956\n",
      "Epoch 13/15\n",
      "\u001b[1m300/476\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 337ms/step - accuracy: 0.2345 - loss: 15.5517"
     ]
    }
   ],
   "source": [
    "# define input shape\n",
    "input_shape = X_test_np[0].shape\n",
    "# Define CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='sigmoid',kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(0.01)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l1_l2(0.01)),\n",
    "    layers.Dense(6, activation='softmax',)  # 6 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape\n",
    "input_shape = X_test_np[0].shape\n",
    "# Define CNN model\n",
    "model1 = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(0.01)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l1_l2(0.01)),\n",
    "    layers.Dense(128, activation='sigmoid',kernel_regularizer=regularizers.l1_l2(0.01)),\n",
    "    layers.Dense(6, activation='softmax',)  # 6 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "history = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape\n",
    "input_shape = X_test_np[0].shape\n",
    "# Define CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(64, (7, 7), strides=(2, 2), activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(192, (3, 3), activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),kernel_regularizer=regularizers.l1(0.01)), \n",
    "    layers.Conv2D(128, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(256, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(256, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(512, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),kernel_regularizer=regularizers.l1(0.01)), \n",
    "    layers.Conv2D(256, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(512, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(512, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),kernel_regularizer=regularizers.l1(0.01)), \n",
    "    layers.Conv2D(512, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),        layers.Conv2D(512, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3), strides=(2, 2),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),        layers.Conv2D(512, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Conv2D(1024, (3, 3),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),        layers.Conv2D(512, (1, 1),activation='relu', padding='same'kernel_regularizer=regularizers.l1(0.01)),    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1_l2(0.01)),\n",
    "    layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1_l2(0.01)),\n",
    "    layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l1_l2(0.01)),\n",
    "    layers.Dense(6, activation='softmax',)  # 6 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd69ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the traing and testing loss vs epoch\n",
    "import matplotlib.pyplot as plt\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_accuracy = history.history['accuracy']\n",
    "test_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "# Visualize accuracy history\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Training accuracy', 'Test accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c802990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Example: Load a pretrained model (e.g., ResNet) for image classification\n",
    "model_pretrain = models.resnet18(pretrained=True)\n",
    "\n",
    "# Define the file path to save the model\n",
    "save_path = 'pretrained_resnet18.pth'\n",
    "\n",
    "# Save the model's state dictionary to a file\n",
    "torch.save(model_pretrain.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945170f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "input_image = X_test[3]\n",
    "#Image.open('..\\Data\\X_Ray Image DataSet\\Guns\\B0009_0001.png').convert('RGB')  # Convert to RGB\n",
    "\n",
    "# Preprocess the image back into jpg\n",
    "# Convert the image data back to the range [0, 255]\n",
    "input_image = Image.fromarray((input_image * 255).astype('uint8'))  # Convert to PIL Image\n",
    "\n",
    "# Convert the image to grayscale\n",
    "input_image_gray = input_image.convert('L')\n",
    "\n",
    "# Display the input image\n",
    "display(input_image_gray)\n",
    "\n",
    "# Preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    # Resize the image to 224x224 pixels\n",
    "    transforms.Resize((224, 224)),  \n",
    "    # Convert to grayscale with 3 channels\n",
    "    transforms.Grayscale(num_output_channels=3),  \n",
    "    # Convert PIL image to PyTorch tensor\n",
    "    transforms.ToTensor(),           \n",
    "    # Normalize the image\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = preprocess(input_image_gray)\n",
    "\n",
    "# Create a PyTorch tensor\n",
    "input_batch = input_tensor.unsqueeze(0)  \n",
    "\n",
    "#  Load a pre-trained model for image classification\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# output results\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "predicted_class = predicted_idx.item()\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce44875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
